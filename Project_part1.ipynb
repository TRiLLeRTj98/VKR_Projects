{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8YWmYI6ehQNi"
   },
   "source": [
    "# Многоклассовая классификация изображений"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2n980XOuhQNu"
   },
   "source": [
    "### Импорт библиотек\n",
    "\n",
    "#### В этом разделе мы импортируем библиотеки, которые будем использовать. В случае, если библиотека отсутсвует, скачаем её через pip install."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OCg-WBvAhQNx"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from tensorflow.keras.layers import Dense, Input, InputLayer, Flatten\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "from tensorflow import keras\n",
    "import matplotlib.image as mpimg\n",
    "import warnings\n",
    "from tensorflow.keras.layers import Conv2D, Flatten, Dense, MaxPool2D, BatchNormalization, GlobalAveragePooling2D\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input, decode_predictions\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_moons\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier,AdaBoostClassifier,GradientBoostingClassifier\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WjVIIbTThQNz"
   },
   "source": [
    "#### Установка размера изображения и исходной папки для загрузки набора данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jRz3qLpJhQN0"
   },
   "outputs": [],
   "source": [
    "IMG_WIDTH=200\n",
    "IMG_HEIGHT=200\n",
    "img_folder=r'/content/training/Coat'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jZFqelDEhQN1"
   },
   "source": [
    "#### Печать случайных 10  изображений из одной из папок"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 272
    },
    "id": "cHtbb28-hQN1",
    "outputId": "fd2cc283-5fb6-41af-d9b9-86e6b7b57587"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "plt.figure(figsize=(15,15))\n",
    "test_folder=r'/content/training/Coat'\n",
    "for j in range(5):\n",
    "    file = random.choice(os.listdir(img_folder))\n",
    "    image_path= os.path.join(img_folder, file)\n",
    "    img=mpimg.imread(image_path)\n",
    "    ax=plt.subplot(1,5,j+1)\n",
    "    ax.title.set_text(file)\n",
    "    plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aq0XJSpphQN3"
   },
   "outputs": [],
   "source": [
    "img_folder=r'/content/training'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L6bahEY1hQN4"
   },
   "source": [
    "#### В этой части загрузим и создалим набор изображений и набор тестовых данных из пользовательских  в качестве входных данных для моделей глубокого обучения. Загрузка будет происходить с помощью Open CV2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NtJZup7EhQN5"
   },
   "source": [
    "#### Создание данных изображения и меток из изображений в папке\n",
    "#### В функции ниже\n",
    "#### Исходная папка — это входной параметр, содержащий изображения для разных классов.\n",
    "#### Прочитаем файл изображения из папки и преобразуйте его в правильный цветовой формат.\n",
    "#### Изменим размер изображения на основе входного размера, необходимого для модели.\n",
    "#### Преобразуем изображение в массив Numpy с float32 в качестве типа данных.\n",
    "#### Нормируем массив изображений, чтобы его значения были уменьшены от 0 до 1 от 0 до 255 для аналогичного распределения данных, что способствует более быстрой сходимости."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VxJ-dmYIhQN6"
   },
   "outputs": [],
   "source": [
    "def create_dataset(img_folder):\n",
    "   \n",
    "    img_data_array=[]\n",
    "    class_name=[]\n",
    "   \n",
    "    for dir1 in os.listdir(img_folder):\n",
    "        for file in os.listdir(os.path.join(img_folder, dir1)):\n",
    "       \n",
    "            image_path= os.path.join(img_folder, dir1,  file)\n",
    "            image= cv2.imread( image_path, cv2.COLOR_BGR2RGB)\n",
    "            image=cv2.resize(image, (IMG_HEIGHT, IMG_WIDTH),interpolation = cv2.INTER_AREA)\n",
    "            image=np.array(image)\n",
    "            image = image.astype('float32')\n",
    "            image /= 255 \n",
    "            img_data_array.append(image)\n",
    "            class_name.append(dir1)\n",
    "    return img_data_array, class_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h9F0TmzWhQN6"
   },
   "outputs": [],
   "source": [
    "img_data, class_name =create_dataset(r'./training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NZGmneY2hQN7"
   },
   "source": [
    "#### Извлечем массив изображений и метки класса\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jqipXdElhQN7",
    "outputId": "8dff80fd-b215-4495-a99e-2768f550e7b0"
   },
   "outputs": [],
   "source": [
    "target_dict={k: v for v, k in enumerate(np.unique(class_name))}\n",
    "target_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pGoMfk45hQN8"
   },
   "source": [
    "#### Преобразование текстовых меток в числовые коды"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "st1zlbk6hQN8"
   },
   "outputs": [],
   "source": [
    "target_val=  [target_dict[class_name[i]] for i in range(len(class_name))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IdcpmiHThQN9"
   },
   "source": [
    "#### Создание простой модели глубокого обучения и ее компиляция"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tVZ30JzGhQN9"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import ticker\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xB2QhIlThQN-"
   },
   "outputs": [],
   "source": [
    "model=tf.keras.Sequential(\n",
    "        [\n",
    "            tf.keras.layers.InputLayer(input_shape=(IMG_HEIGHT,IMG_WIDTH, 3)),\n",
    "            tf.keras.layers.Conv2D(filters=32, kernel_size=3, strides=(2, 2), activation='relu'),\n",
    "            tf.keras.layers.Conv2D(filters=64, kernel_size=3, strides=(2, 2), activation='relu'),\n",
    "            tf.keras.layers.Flatten(),\n",
    "            tf.keras.layers.Dense(9)\n",
    "        ])\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "x6IgrxrBhQN-",
    "outputId": "a247d7b0-5c37-48c7-90d4-945e73562573"
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P4M2CbPPhQN_"
   },
   "source": [
    "#### Фильтры\n",
    "\n",
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-mVv5fDQhQN_"
   },
   "source": [
    "Первый обязательный параметр Conv2D — это количество фильтров, которые будет изучать сверточный слой.\n",
    "\n",
    "Слои в ранней сетевой архитектуре (т. е. ближе к фактическому входному изображению) изучают меньше сверточных фильтров, в то время как более глубокие слои в сети (т. е. ближе к выходным прогнозам) изучают больше фильтров.\n",
    "\n",
    "Промежуточные слои Conv2D изучают больше фильтров, чем ранние слои Conv2D, но меньше фильтров, чем слои, расположенные ближе к выходным данным."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yW3SYMzMhQOA"
   },
   "source": [
    "#### Размер_ядра\n",
    "\n",
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3p2S20qGhQOA"
   },
   "source": [
    "Второй обязательный параметр, который необходимо предоставить классу Keras Conv2D, — это kernel_size, состоящий из двух кортежей, указывающий ширину и высоту окна 2D-свертки.\n",
    "\n",
    "Размер ядра также должен быть нечетным целым числом.\n",
    "\n",
    "Типичные значения для kernel_size включают: (1, 1) , (3, 3) , (5, 5) , (7, 7) . Редко можно увидеть размеры ядра больше 7×7.\n",
    "\n",
    "Итак, когда вы используете каждый из них?\n",
    "\n",
    "Если ваши входные изображения больше 128 × 128, вы можете использовать размер ядра> 3, чтобы помочь (1) изучить более крупные пространственные фильтры и (2) помочь уменьшить размер объема.\n",
    "\n",
    "Другие сети, такие как VGGNet, используют исключительно фильтры (3, 3) во всей сети.\n",
    "\n",
    "Более продвинутые архитектуры, такие как Inception, ResNet и SqueezeNet, проектируют целые микроархитектуры, представляющие собой «модули» внутри сети, которые изучают локальные особенности в разных масштабах (например, 1×1, 3×3 и 5×5), а затем объединяют выходы."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3N51qWeShQOB"
   },
   "source": [
    "### СДВИГИ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MUALsxnJhQOB"
   },
   "source": [
    "Параметр strides представляет собой набор из двух целых чисел, указывающих «шаг» свертки по осям x и y входного объема.\n",
    "\n",
    "Значение шага по умолчанию равно (1, 1) , что означает, что:\n",
    "\n",
    "Данный сверточный фильтр применяется к текущему местоположению входного объема.\n",
    "Фильтр делает шаг на 1 пиксель вправо и снова фильтр применяется к входному объему.\n",
    "Этот процесс выполняется до тех пор, пока мы не достигнем крайней правой границы объема, в котором мы перемещаем наш фильтр на один пиксель вниз, а затем снова начинаем с крайнего левого.\n",
    "Обычно вы оставляете параметр strides со значением по умолчанию (1, 1); однако иногда можно увеличить его до (2, 2), чтобы уменьшить размер выходного тома (поскольку размер шага фильтра больше)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RFUZC1tQhQOB"
   },
   "source": [
    "### Функция активации\n",
    "\n",
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Njd2FUnjhQOB"
   },
   "source": [
    "Параметр активации для класса Conv2D — это просто параметр удобства, позволяющий указать строку, указывающую имя функции активации, которую мы хотим применить после выполнения свертки.\n",
    "\n",
    "В нашем примере мы выполняем свертку, а затем применяем функцию активации ReLU:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f50SAah_hQOC"
   },
   "source": [
    "### Наконец-то мы подогнали наш набор данных для обучения модели. Мы можем использовать массив Numpy в качестве входных данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "F4jWgHY8hQOC",
    "outputId": "9319df3a-a1c1-46e6-b577-6797e1ddc838"
   },
   "outputs": [],
   "source": [
    "history = model.fit(x=np.array(img_data, np.float32), y=np.array(list(map(int,target_val)), np.float32),validation_split=0.2, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e0zP6UJbhQOC",
    "outputId": "9af4a0bd-bb07-4de8-e633-ee2ee5469360"
   },
   "outputs": [],
   "source": [
    "print(history.history.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4WnfMj6Zmblf"
   },
   "outputs": [],
   "source": [
    "# summarize history for accuracy\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GW-3-gMthQOD"
   },
   "source": [
    "Как мы видим, при небольшом количестве данных нейронные сети дают очень плохой результат  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SjF22Q0PhQOD"
   },
   "source": [
    "#### Давайте попытаемся использовать нащи данные для обучения на более простых моделях, чем нейронные сети, к примеру на ансамблевом обучении. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qtM_JUkhhQOD"
   },
   "outputs": [],
   "source": [
    "nsamples, nx, ny,_ = np.array(img_data).shape\n",
    "img_data = np.array(img_data).reshape((nsamples,nx*ny*3))\n",
    "X_train, X_test, y_train, y_test = train_test_split(img_data, target_val, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z5Hnj1DDhQOD"
   },
   "source": [
    "#### Ансамблевое обучение в целом представляет собой модель, которая делает прогнозы на основе ряда различных моделей. Комбинируя отдельные модели, модель ансамбля становится более гибкой🤸‍♀️ (меньше предвзятости) и менее чувствительной к данным🧘‍♀️ (меньше дисперсии)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "33OpjxBIhQOE"
   },
   "source": [
    "Двумя наиболее популярными ансамблевыми методами являются бэггинг и бустинг.\n",
    "\n",
    "Бэггинг: параллельное обучение нескольких отдельных моделей. Каждая модель обучается на случайном подмножестве данных\n",
    "\n",
    "Бустинг: последовательное обучение группы отдельных моделей. Каждая отдельная модель учится на ошибках, допущенных предыдущей моделью."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h2nmDRcvhQOE"
   },
   "source": [
    "### 1 Случайный лес\n",
    "Случайный лес — это модель ансамбля, использующая бэггинг в качестве метода ансамбля и дерево решений в качестве отдельной модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "t7MKVqq5hQOE",
    "outputId": "b7f30ed4-b3e4-4bca-c55a-54e8fa524d83"
   },
   "outputs": [],
   "source": [
    "# Шаг 1: Подгонка модели дерева решений\n",
    "clf = DecisionTreeClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SEfxhsIthQOE",
    "outputId": "45f4006b-5da1-41cc-c8f0-815160672a5e"
   },
   "outputs": [],
   "source": [
    "# Шаг 2: Сопоставьте модель случайного леса\n",
    "clf = RandomForestClassifier(n_estimators=100, max_features=\"auto\",random_state=0)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hzKb4OFVhQOG"
   },
   "source": [
    "### AdaBoost (адаптивное повышение)\n",
    "AdaBoost — это повышающая ансамблевая модель, которая особенно хорошо работает с деревом решений. Ключом к модели повышения является обучение на предыдущих ошибках, т.е. точки данных неправильной классификации.\n",
    "AdaBoost учится на ошибках, увеличивая вес ошибочно классифицированных точек данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vdXDs0jOhQOG",
    "outputId": "99b35af6-655e-4c66-bff5-5cf5abb82c2e"
   },
   "outputs": [],
   "source": [
    "# Шаг 3: модель AdaBoost\n",
    "clf = AdaBoostClassifier(n_estimators=100)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HJHiYSlThQOG"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "params = {\n",
    "     'n_estimators': np.arange(10,300,100),\n",
    "     'learning_rate': [0.01, 0.05, 0.1, 1],\n",
    " }\n",
    "grid_cv = GridSearchCV(AdaBoostClassifier(), param_grid= params, cv=5, n_jobs=-1)\n",
    "grid_cv.fit(X_train, y_train)\n",
    "grid_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4Epmz1sn07Jt"
   },
   "outputs": [],
   "source": [
    "\n",
    "accuracy_score(y_test, grid_cv.predict(grid_cv))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S3osEyXvhQOG"
   },
   "source": [
    "### Градиентный бустинг\n",
    "Градиентный бустинг — еще одна модель повышения. Ключом к повышению эффективности модели является обучение на предыдущих ошибках.\n",
    "Gradient Boosting учится на ошибке — остаточной ошибке напрямую, а не обновляет веса точек данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_CX3DKLjhQOH"
   },
   "outputs": [],
   "source": [
    "# Шаг 4: модель повышения градиента\n",
    "clf = GradientBoostingClassifier(n_estimators=100)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "G0R6YilBhQOH"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import make_scorer\n",
    "#создание параметра оценки:\n",
    "\n",
    "scoring = {'accuracy': make_scorer(accuracy_score),\n",
    "           'precision': make_scorer(precision_score),'recall':make_scorer(recall_score)}\n",
    "\n",
    "# Пример параметра\n",
    "parameters = {\n",
    "    \"loss\":[\"deviance\"],\n",
    "    \"learning_rate\": [0.01, 0.025, 0.05, 0.075, 0.1, 0.15, 0.2],\n",
    "    \"min_samples_split\": np.linspace(0.1, 0.5, 12),\n",
    "    \"min_samples_leaf\": np.linspace(0.1, 0.5, 12),\n",
    "    \"max_depth\":[3,5,8],\n",
    "    \"max_features\":[\"log2\",\"sqrt\"],\n",
    "    \"criterion\": [\"friedman_mse\",  \"mae\"],\n",
    "    \"subsample\":[0.5, 0.618, 0.8, 0.85, 0.9, 0.95, 1.0],\n",
    "    \"n_estimators\":[10]\n",
    "    }\n",
    "# передача функции подсчета очков в GridSearchCV\n",
    "clf = GridSearchCV(GradientBoostingClassifier(), parameters,scoring=scoring,refit=False,cv=2, n_jobs=-1)\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "# преобразование clf.cv_results в фрейм данных\n",
    "df=pd.DataFrame.from_dict(clf.cv_results_)\n",
    "#здесь Возможные входные данные для перекрестной проверки: cv=2, есть два разделения split0 и split1\n",
    "df[['split0_test_accuracy','split1_test_accuracy','split0_test_precision','split1_test_precision','split0_test_recall','split1_test_recall']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qHOAsFVlhQOH"
   },
   "outputs": [],
   "source": [
    "#найти лучший параметр на основе precision_score\n",
    "# взяв среднее значение по показателю \"точность_показателя\"\n",
    "df['accuracy_score']=(df['split0_test_accuracy']+df['split1_test_accuracy'])/2\n",
    "\n",
    "df.loc[df['accuracy_score'].idxmax()]['params']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KBK4QmyihQOH"
   },
   "source": [
    "В целом, ансамблевое обучение очень мощное и может использоваться не только для решения задачи классификации, но и для регрессии. Но в задачах классификации изображений они все же не пользуются большой популярностью, так как при больших массивах данных становятся просто напросто очень долгими и не такими эффективными, как нейронные сети."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Untitled.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
